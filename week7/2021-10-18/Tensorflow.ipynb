{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beneficial-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respected-affiliate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train , X_test = X_train/255.0, X_test/255.0\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-female",
   "metadata": {},
   "source": [
    "## (1) Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuing-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medical-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 18s 8ms/step - loss: 0.2018 - accuracy: 0.9389\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0321 - accuracy: 0.9894\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "313/313 - 2s - loss: 0.0538 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05379066616296768, 0.9886999726295471]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-giant",
   "metadata": {},
   "source": [
    "### CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spectacular-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "compressed-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caring-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 13s 6ms/step - loss: 4.0487 - accuracy: 0.0897\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.9783 - accuracy: 0.2701\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6207 - accuracy: 0.3378\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 2.4079 - accuracy: 0.3821\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2340 - accuracy: 0.4210\n",
      "313/313 - 1s - loss: 2.5743 - accuracy: 0.3623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5743465423583984, 0.36230000853538513]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-floor",
   "metadata": {},
   "source": [
    "## Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adequate-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "inputs = keras.Input(shape=(28,28,1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accompanied-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2114 - accuracy: 0.9335\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0328 - accuracy: 0.9895\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0194 - accuracy: 0.9935\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "313/313 - 1s - loss: 0.0453 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04528305307030678, 0.987500011920929]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-neighborhood",
   "metadata": {},
   "source": [
    "### CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "measured-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "commercial-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32,32,3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "respective-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0147 - accuracy: 0.0922\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 3.0166 - accuracy: 0.2600\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6660 - accuracy: 0.3305\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 2.4369 - accuracy: 0.3796\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2656 - accuracy: 0.4187\n",
      "313/313 - 1s - loss: 2.5804 - accuracy: 0.3591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5803825855255127, 0.35910001397132874]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-command",
   "metadata": {},
   "source": [
    "## Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saving-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attended-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2219 - accuracy: 0.9311\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0332 - accuracy: 0.9893\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "313/313 - 1s - loss: 0.0406 - accuracy: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04060938581824303, 0.9897000193595886]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-speaker",
   "metadata": {},
   "source": [
    "### CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aware-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mexican-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.pool = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exclusive-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0031 - accuracy: 0.0988\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.9299 - accuracy: 0.2804\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 2.5663 - accuracy: 0.3530\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3393 - accuracy: 0.4041\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1471 - accuracy: 0.4412\n",
      "313/313 - 1s - loss: 2.5902 - accuracy: 0.3647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.59017276763916, 0.36469998955726624]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-position",
   "metadata": {},
   "source": [
    "# Gradient Tape\n",
    "\n",
    "- Forward pass로 진행된 모든 연산의 중간 레이어값을 tape에 기록하고, 이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brief-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "#모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.pool = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "traditional-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-groove",
   "metadata": {},
   "source": [
    "- 위와 같이 loss, optimizer를 지정해주면 내부적으로 매 스텝이 진행될 때마다 model.compile() 안에서 자동으로 학습이 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "racial-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "#tf.GradientTape() 를 활용한 train step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "united-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0100 - accuracy: 0.0957\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.9719 - accuracy: 0.2669\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6070 - accuracy: 0.3445\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3760 - accuracy: 0.3899\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1787 - accuracy: 0.4329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f06261f06d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lasting-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 5.6303\n",
      "Epoch 1: last batch loss = 4.3588\n",
      "Epoch 2: last batch loss = 0.0431\n",
      "Epoch 3: last batch loss = 0.1761\n",
      "Epoch 4: last batch loss = 2.5353\n",
      "It took 113.75798654556274 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                X_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(X_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                X_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-converter",
   "metadata": {},
   "source": [
    "tf.GradientTape()를 활용하여 model.compile(), model.fit() 안에 있던 한 스텝의 학습 단계를 끄집어내서 자유롭게 재구성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "interested-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1848"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_test, batch_size=X_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-banana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
