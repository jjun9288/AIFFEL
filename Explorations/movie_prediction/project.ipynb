{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historical-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "friendly-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:40:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-20 13:44:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time\n",
       "31            1    3186       4 2000-12-31 22:00:19\n",
       "22            1    1270       5 2000-12-31 22:00:55\n",
       "27            1    1721       4 2000-12-31 22:00:55\n",
       "37            1    1022       5 2000-12-31 22:00:55\n",
       "24            1    2340       3 2000-12-31 22:01:43\n",
       "...         ...     ...     ...                 ...\n",
       "1000019    6040    2917       4 2001-08-10 14:40:29\n",
       "999988     6040    1921       4 2001-08-10 14:41:04\n",
       "1000172    6040    1784       3 2001-08-10 14:41:04\n",
       "1000167    6040     161       3 2001-08-10 14:41:26\n",
       "1000042    6040    1221       4 2001-08-20 13:44:15\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose/data') \n",
    "train_path = data_path / 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', \n",
    "                       header=None, usecols=[0, 1, 2, 3], \n",
    "                       names = ['UserId', 'ItemId', 'Rating', 'Time'],\n",
    "                       dtype={0: np.int32, 1: np.int32, 2: np.int32}, \n",
    "                       nrows=nrows)\n",
    "    return data\n",
    "data = load_data(train_path, None)\n",
    "data['Time'] = pd.to_datetime(data['Time'], unit='s')\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-casting",
   "metadata": {},
   "source": [
    "## 1. Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-calgary",
   "metadata": {},
   "source": [
    "##### Session length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dress-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserId\n",
       "1        53\n",
       "2       129\n",
       "3        51\n",
       "4        21\n",
       "5       198\n",
       "       ... \n",
       "6036    888\n",
       "6037    202\n",
       "6038     20\n",
       "6039    123\n",
       "6040    341\n",
       "Length: 6040, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length = data.groupby('UserId').size()\n",
    "user_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adolescent-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96.0, 165.5975165562914)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length.median(), user_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hungry-perry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2314)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length.min(), user_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "joint-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906.659999999998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_length.quantile(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-compatibility",
   "metadata": {},
   "source": [
    "##### Session time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "competitive-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-04-25 23:05:32\n",
      "2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "oldest, latest = data['Time'].min(), data['Time'].max()\n",
    "print(oldest) \n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dependent-industry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-reputation",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "protective-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_view) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_view)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    user_len = data.groupby('UserId').size()\n",
    "    user_use = user_len[user_len >= shortest].index\n",
    "    data = data[data['UserId'].isin(user_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "arbitrary-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.5975165562914\n",
      "269.88909875876953\n"
     ]
    }
   ],
   "source": [
    "user_len = data.groupby('UserId').size()\n",
    "item_popular = data.groupby('ItemId').size()\n",
    "\n",
    "print(user_len.mean())\n",
    "print(item_popular.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coated-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000019</th>\n",
       "      <td>6040</td>\n",
       "      <td>2917</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:40:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999988</th>\n",
       "      <td>6040</td>\n",
       "      <td>1921</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000172</th>\n",
       "      <td>6040</td>\n",
       "      <td>1784</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000167</th>\n",
       "      <td>6040</td>\n",
       "      <td>161</td>\n",
       "      <td>3</td>\n",
       "      <td>2001-08-10 14:41:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000042</th>\n",
       "      <td>6040</td>\n",
       "      <td>1221</td>\n",
       "      <td>4</td>\n",
       "      <td>2001-08-20 13:44:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000095 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time\n",
       "31            1    3186       4 2000-12-31 22:00:19\n",
       "22            1    1270       5 2000-12-31 22:00:55\n",
       "27            1    1721       4 2000-12-31 22:00:55\n",
       "37            1    1022       5 2000-12-31 22:00:55\n",
       "24            1    2340       3 2000-12-31 22:01:43\n",
       "...         ...     ...     ...                 ...\n",
       "1000019    6040    2917       4 2001-08-10 14:40:29\n",
       "999988     6040    1921       4 2001-08-10 14:41:04\n",
       "1000172    6040    1784       3 2001-08-10 14:41:04\n",
       "1000167    6040     161       3 2001-08-10 14:41:26\n",
       "1000042    6040    1221       4 2001-08-20 13:44:15\n",
       "\n",
       "[1000095 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cleanse_recursive(data, shortest=4, least_view=2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sufficient-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-checkout",
   "metadata": {},
   "source": [
    "### Train / Valid / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "owned-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    user_last_time = data.groupby('UserId')['Time'].max().sort_values()\n",
    "    user_in_train = data[data['Time'] < final_time - dt.timedelta(n_days)]\n",
    "    user_in_test = data[data['Time'] >= final_time - dt.timedelta(n_days)]\n",
    "    \n",
    "    before_date = user_in_train\n",
    "    after_date = user_in_test\n",
    "    return before_date, after_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "promising-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=180)\n",
    "tr, val = split_by_date(tr, n_days=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optimum-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t Users: {data[\"UserId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bottom-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* train Set Stats Info\n",
      "\t Events: 978986\n",
      "\t Users: 6038\n",
      "\t Items: 3592\n",
      "\t First Time : 2000-04-25 23:05:32\n",
      "\t Last Time : 2002-03-05 04:19:56\n",
      "\n",
      "* valid Set Stats Info\n",
      "\t Events: 12289\n",
      "\t Users: 399\n",
      "\t Items: 2624\n",
      "\t First Time : 2002-03-05 04:21:07\n",
      "\t Last Time : 2002-09-01 04:20:59\n",
      "\n",
      "* test Set Stats Info\n",
      "\t Events: 8820\n",
      "\t Users: 339\n",
      "\t Items: 2330\n",
      "\t First Time : 2002-09-01 19:41:39\n",
      "\t Last Time : 2003-02-28 17:49:50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "banned-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  \n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "systematic-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = data_path / 'processed'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tr.to_pickle(save_path / 'train.pkl')\n",
    "val.to_pickle(save_path / 'valid.pkl')\n",
    "test.to_pickle(save_path / 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-undergraduate",
   "metadata": {},
   "source": [
    "### Session Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "auburn-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.session_idx = np.arange(self.df['UserId'].nunique())  # indexing to UserId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['UserId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('UserId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cubic-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>item_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000138</th>\n",
       "      <td>6040</td>\n",
       "      <td>858</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 23:05:32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999873</th>\n",
       "      <td>6040</td>\n",
       "      <td>593</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:05:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000153</th>\n",
       "      <td>6040</td>\n",
       "      <td>2384</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 23:05:54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000007</th>\n",
       "      <td>6040</td>\n",
       "      <td>1961</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 23:06:17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000192</th>\n",
       "      <td>6040</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:06:17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999877</th>\n",
       "      <td>6040</td>\n",
       "      <td>1419</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-04-25 23:07:36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999868</th>\n",
       "      <td>6040</td>\n",
       "      <td>573</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 23:07:36</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999980</th>\n",
       "      <td>6040</td>\n",
       "      <td>3505</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 23:07:36</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999967</th>\n",
       "      <td>6040</td>\n",
       "      <td>3111</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:07:36</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999920</th>\n",
       "      <td>6040</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 23:07:36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserId  ItemId  Rating                Time  item_idx\n",
       "1000138    6040     858       4 2000-04-25 23:05:32         0\n",
       "999873     6040     593       5 2000-04-25 23:05:54         1\n",
       "1000153    6040    2384       4 2000-04-25 23:05:54         2\n",
       "1000007    6040    1961       4 2000-04-25 23:06:17         3\n",
       "1000192    6040    2019       5 2000-04-25 23:06:17         4\n",
       "999877     6040    1419       3 2000-04-25 23:07:36         5\n",
       "999868     6040     573       4 2000-04-25 23:07:36         6\n",
       "999980     6040    3505       4 2000-04-25 23:07:36         7\n",
       "999967     6040    3111       5 2000-04-25 23:07:36         8\n",
       "999920     6040     213       5 2000-04-25 23:07:36         9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset = SessionDataset(tr)\n",
    "tr_dataset.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adjacent-maintenance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     53,    182, ..., 978522, 978645, 978986], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "meaningful-technology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 6035, 6036, 6037])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "matched-invitation",
   "metadata": {},
   "source": [
    "### Session Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "timely-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "        \n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]  \n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i  \n",
    "            if new_session > self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "victorian-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          UserId  ItemId  Rating                Time  item_idx\n",
       "1000138    6040     858       4 2000-04-25 23:05:32         0\n",
       "999873     6040     593       5 2000-04-25 23:05:54         1\n",
       "1000153    6040    2384       4 2000-04-25 23:05:54         2\n",
       "1000007    6040    1961       4 2000-04-25 23:06:17         3\n",
       "1000192    6040    2019       5 2000-04-25 23:06:17         4\n",
       "...         ...     ...     ...                 ...       ...\n",
       "565308     3475    1266       3 2002-03-05 04:14:13      1106\n",
       "565831     3475    2944       3 2002-03-05 04:14:13       781\n",
       "565367     3475     920       3 2002-03-05 04:14:13       177\n",
       "565317     3475     596       2 2002-03-05 04:18:51       897\n",
       "565881     3475      99       2 2002-03-05 04:19:56      2807\n",
       "\n",
       "[978986 rows x 5 columns]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "widespread-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ex = iter(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "three-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Item Idx are : [  0  53 106 210]\n",
      "Label Item Idx are :       [  1  54 177 211]\n",
      "Previous Masked Input Idx are []\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-enforcement",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "satisfied-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "turned-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "marked-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "smart-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_users = tr['UserId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "args = Args(tr, val, test, batch_size=256, hsz=50, drop_rate=0.1, lr=0.001, epochs=5, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "green-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['UserId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다. \n",
    "                                             # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['UserId'].nunique()\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "#         pred_arg = tf.nn.top_k(pred, k=124, sorted=True)[1]  # softmax 값이 큰 순서대로 sorting 합니다.\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')\n",
    "    \n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "renewable-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "whole-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train:   0%|          | 0/7601 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(128, 1, 3592)]          0         \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    [(128, 100), (128, 100)]  1108200   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (128, 100)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, 3592)               362792    \n",
      "=================================================================\n",
      "Total params: 1,470,992\n",
      "Trainable params: 1,470,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 7433/7601 [03:20<00:04, 37.10it/s, accuracy=0.00781, train_loss=7.17]\n",
      "Evaluation:  45%|████▍     | 41/92 [00:31<00:39,  1.30it/s]\n",
      "Train:   0%|          | 0/7601 [00:00<?, ?it/s, accuracy=0.00781, train_loss=6.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 1: 0.084985\n",
      "\t - MRR@20    epoch 1: 0.019013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 7433/7601 [03:18<00:04, 37.54it/s, accuracy=0.0234, train_loss=6.9]  \n",
      "Evaluation:  45%|████▍     | 41/92 [00:31<00:39,  1.30it/s]\n",
      "Train:   0%|          | 0/7601 [00:00<?, ?it/s, accuracy=0.0156, train_loss=6.18] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 2: 0.099466\n",
      "\t - MRR@20    epoch 2: 0.023123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 7433/7601 [03:16<00:04, 37.89it/s, accuracy=0.0234, train_loss=6.76] \n",
      "Evaluation:  45%|████▍     | 41/92 [00:31<00:38,  1.31it/s]\n",
      "Train:   0%|          | 0/7601 [00:00<?, ?it/s, accuracy=0.0234, train_loss=6.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 3: 0.107470\n",
      "\t - MRR@20    epoch 3: 0.025574\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 7433/7601 [03:15<00:04, 37.95it/s, accuracy=0.0234, train_loss=6.66] \n",
      "Evaluation:  45%|████▍     | 41/92 [00:31<00:38,  1.32it/s]\n",
      "Train:   0%|          | 0/7601 [00:00<?, ?it/s, accuracy=0.0312, train_loss=6.38] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 4: 0.111280\n",
      "\t - MRR@20    epoch 4: 0.027570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  98%|█████████▊| 7433/7601 [03:18<00:04, 37.42it/s, accuracy=0.0234, train_loss=6.62] \n",
      "Evaluation:  45%|████▍     | 41/92 [00:31<00:39,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Recall@20 epoch 5: 0.110137\n",
      "\t - MRR@20    epoch 5: 0.028865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(tr, val, test, batch_size=128, hsz=100, drop_rate=0.25, lr=0.001, epochs=5, k=20)\n",
    "model = create_model(args)\n",
    "train_model(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-switch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
